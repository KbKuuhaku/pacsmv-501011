
[model.vae]

[model.unet]
corpus_length = 10  # MNIST

in_channels = 4
out_channels = 4
num_res_blocks = 2

model_channels = 320  
channel_multipliers = [1, 2, 4, 4]  # multipliers on `model_channels` on each level
attention_levels = [1, 2, 4]  # where the attention block should be added

[model.unet.transformer]
context_dim = 768
num_heads = 8
num_layers = 1 # ?
